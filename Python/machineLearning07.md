# 머신러닝_07

### 앙상블

- 하나의 분류기보다 집단지성처럼 여러개의 분류기를 활용

#### 부스팅

- GPU  병렬 처리 가능
  - 하이퍼 파라미터 튜닝 가능
- early stoping 가능
  - 어느 정도 학습하다가 성능이 안 좋아지면 학습 멈춤

- 가지 치기 가능
  - 의사 결정을 가지 쳐서 성능을 높일 수 있음

#### 특징

- 단일 모델의 약점을 다수의 모델들을 결합하여 보완
- 랜덤 포레스트 및 뛰어난 부스팅 알고리즘들은 모두 결정 트리 알고리즘을 기반 알고리즘으로 적용함
- 결정트리의 단점인 과적합(오버 피팅)을 수십~ 수천개의 많은 분류기를 결합해 보완하고 장점인 직관적인 분류 기준은 강화됨

### 랜덤포레스트

- 배깅의 대표적인 알고리즘
- 여러개의 결정트리 활용

##### 배깅이란?

- bootstrap Aggregating의 약자
- 동일한 알고리즘으로 여러 분류기를 만들어 보팅으로 최종 결정하는 알고리즘

**진행 방식**

1. 동일한 알고리즘을 사용하는 일정 수의 분류기 생성
2. 각각의 분류기는 **부트스트래핑**방식으로 생성된 샘플데이터를 학습
   1. **부트스트래핑** : 전제 데이테에서 일부 데이터의 중첩을 허용하는 방식 : 복원추출
3. 최종적으로 모든 분류기가 보팅을 통해 예측 결정

##### 장점

- 앙상블방식의 알고리즘 중 수행속도가 빠르다.
- 다양한 데이터 세트에서 좋은 성능

##### 단점

- 튜닝을 위한 시간이 많이 든다.

### HAR 데이터를 이용해서 RandomForest 배깅을 이용한 분류예측

```python
X_train, X_test, y_train, y_test  
```

- 학습 데이터와 test 데이터는 불러왔음

```python
rf_model = RandomForestClassifier(random_state=0)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)
print('answer',y_test)
```

- 학습, 예측을 하였음