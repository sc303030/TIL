### 분류

- 대표적인 분류 알고리즘
  - 나이브 베이즈
    - 베이즈 통계와 생성 모델에기반
  - 로지스틱 회귀
    - 독리변수와 종속변수의 선형 관계에 기반
  - 결정트리
    - 데이터 균일도에 따른 규칙 기반
  - 서포트 벡터 머신
    - 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아줌
  - 최소 근접 알고리즘
    - 근접 거리를 기준
  - 심층 연결 기반의 신경망
  - 앙상블
    - 서로 다른(또는 같은) 머신러닝 알고리즘을 결합

#### 결정 트리

- 매우 쉽고 유연하게 적용될 수 있는 알고리즘
- 데이터의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적음
- 데이터에 있는 규칙을 학습해 자동으로  트리 기반의 규측을 만듦( IF- Else기반 규칙)
  - 어떤 규칙을 만드는지에 따라 알고리즘 성능을 가름
- 예측 성능을 향상시키기 위해 복잡한 규칙 구조를 가져야 하며, 이로 인한 과적합이 발생해 반대로 예측 성능 저하 가능성이 있다는 단점
  - 검증 단계에서 예측성 저하

##### 결정트리의 구조

- 루프노드 : 시작점
- 리프노드 : 결정된 클래스 값
- 규칙 노드(내부노드) : 데이터 세트의 피처가 결합해 만들어진 분류를 위한 규칙 조건

##### 정보 균일도 측정 방법

- 정보 이득
  - 엔트로피 개념 기반
    - 엔트로피가 높음
      - 서로 다른 값이 섞여있음
      - 규칙을 많이 만들어야 한다.
    -  엔트로피 낮음
      - 같은 값이 섞여 있음
    - 1 - 엔프로피 지수
- 지니 계수
  - 지니계수가 0이 가장 평등
    - if 0 이면 더 이상 규칙 생성 안해도 됨 : 규칙 노드가 됨
  - 1에 가까우면 불평등
    - 혼잡도가 높은 것
    - 규칙을 만들어야 한다.
- 조건을 찾아 계속 루핑

##### 결정 트리 주요 하이퍼 파라미터

- max_depth
  - 트리의 최대 깊이 규정
  - 디폴트 None
- max_features
  - 최적의 분할을 위해 고려할 최대 피처 개수
  - 디폴트는 None으로 데이터 세으틔 모든 피처를 사용해 분할 수행

- min_sample_split
  - 노드를 분할하기 위한 최소한의 샘플 데이터 수로 과적합을 제어
  - 디폴트 2
-  min_sample_leaf
  - 말단 노드가 되기 위한 최소한의 샘플 데이터 수
- max_leaf_nodes
  - 말단 노드의 최대 개수

##### 결정 트리의  feature 선택 중요도

- sklearn의 DecisionClassifier 객체는 feature_importances_ 을 통해 학습/예측을 위해서 중요한 feature 들을 선택 할 수 있게 정보 제공

#### 앙상블

- 위의 단점이 앙상블레서는 장점
- 집단 지성의 결론을 도출
- 매우 많은 여러 개의 약한 학습기(예측 성능이 상대적으로 떨어지는 학습 알고리즘)를 결합해 확률적으로 보완과 오류가 발생한 부분에 대한 가중치를 계속 업데이트하여 예측 성능 향상
- 결정 트리가 좋은 약한 학습기가 됨
  -  GDM, XGBoost, LightGBM

### iris data를 이용한 의사결졍 트리 피터 중요도

#### 분류기 생성

